{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `GoPiGo` Autopilot with Keras & TensorFlow\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import pickle\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import callbacks\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load driving data from AWS\n",
    "\n",
    ">The dataset is composed of ~7900 images and steering angles collected as I manually drove the car. About 2/3 of the images are with the car between the lines. The other third is of the car starting off course and correcting by driving back to between the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# driving data size: (450Mb) \n",
    "driv_data = 'https://s3.amazonaws.com/donkey_resources/indoor_lanes.pkl'\n",
    "fpath, headers = urllib.request.urlretrieve(driv_data)\n",
    "print(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fpath, 'rb') as f:\n",
    "    X, Y = pickle.load(f)\n",
    "    \n",
    "print('X.shape: ', X.shape)\n",
    "print('Y.shape: ', Y.shape)\n",
    "imshow(X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle both X and Y the same way\n",
    "def unison_shuffled_cp(X, Y):\n",
    "    assert len(X) == len(Y)\n",
    "    p = np.random.permutation(len(X))\n",
    "    return X[p], Y[p]\n",
    "\n",
    "shuffled_X, shuffled_Y = unison_shuffled_cp(X,Y)\n",
    "\n",
    "len(shuffled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80% of data used for training\n",
    "test_cutoff = int(len(X) * 0.8)\n",
    "# 10% of data used for validation and test data \n",
    "val_cutoff = test_cutoff + int(len(X) * 0.1)\n",
    "\n",
    "train_X, train_Y = shuffled_X[:test_cutoff], shuffled_Y[:test_cutoff]\n",
    "val_X, val_Y = shuffled_X[test_cutoff:val_cutoff], shuffled_Y[test_cutoff:val_cutoff]\n",
    "test_X, test_Y = shuffled_X[val_cutoff:], shuffled_Y[val_cutoff:]\n",
    "\n",
    "len(train_X) + len(val_X) + len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flipped = np.array([np.fliplr(i) for i in train_X])\n",
    "Y_flipped = np.array([-i for i in train_Y])\n",
    "train_X = np.concatenate([train_X, X_flipped])\n",
    "train_Y = np.concatenate([train_Y, Y_flipped])\n",
    "len(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build a driving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "angle_in = Input(shape=(1,), name='angle_in')\n",
    "\n",
    "x = Conv2D(8, (3, 3))(img_in)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "merged = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(merged)\n",
    "x = Activation('linear')(x)\n",
    "x = Dropout(.2)(x)\n",
    "\n",
    "angle_out = Dense(1, name='angle_out')(x)\n",
    "\n",
    "model = Model(inputs=[img_in], outputs=[angle_out])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = tf.compat.as_bytes(\"<stripped %d bytes>\"%size)\n",
    "    return strip_def\n",
    "  \n",
    "def rename_nodes(graph_def, rename_func):\n",
    "    res_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = res_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        n.name = rename_func(n.name)\n",
    "        for i, s in enumerate(n.input):\n",
    "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
    "    return res_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "  \n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "\n",
    "show_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.expanduser('~/best_autopilot.hdf5')\n",
    "\n",
    "# Save the model after each epoch if the validation loss improved.\n",
    "save_best = callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, \n",
    "                                     save_best_only=True, mode='min')\n",
    "\n",
    "# Stop training if the validation loss doesn't improve for 5 consecutive epochs.\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, \n",
    "                                     verbose=0, mode='auto')\n",
    "\n",
    "callbacks_list = [save_best, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_X, train_Y, batch_size=64, epochs=4, validation_data=(val_X, val_Y), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "test_P = model.predict(test_X)\n",
    "test_P = test_P.reshape((test_P.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'predicted':test_P, 'actual':test_Y})\n",
    "ax = df.plot.scatter('predicted', 'actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    " Comparsion:\n",
    "\n",
    "![W.Roscoe - eval1](img/eval1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = model.predict(X[:700])\n",
    "#predict outputs nested arrays so we need to reshape to plot.\n",
    "P = P.reshape((P.shape[0],)) \n",
    "\n",
    "ax = pd.DataFrame({'predicted':P, 'actual':Y[:700]}).plot()\n",
    "ax.set_ylabel(\"steering angle\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Comparsion:\n",
    "\n",
    "![W.Roscoe -- eval2](img/eval2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\n",
    "-\n",
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Reference:`\n",
    "Will Roscoe - Lane Following Autopilot with Keras & Tensorflow\n",
    "https://wroscoe.github.io/keras-lane-following-autopilot.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
